# The 4D Framework ("The 4 Competencies")

# Delegation

Goal: gaining a clear vision of your task and AI's role in the process

> The goal is not to have AI automate everything, but to create an effective AI partnership for any given taks/goal.
>
> The most successful AI collaborators are experts in their fields first and AI delegators second

1. Problem Awareness
    1. What are you trying to create or solve?
    2. Do you have a clear vision or goal in mind?
    3. What does success look like?
    4. What kind of thinking and work is needed to get there?
        1. Are there areas that are time-consuming?
        2. Areas of uncertainty where a trusted thinker could help?
        3. Areas requiring critical judgement?
        4. Areas of ignorance where more data is needed?
2. Platform Awareness
    1. Do you know which models perform best for the type of work you're doing?
    2. Do you know which models optimize for speed over depth or creativity over accuracy?
    3. Landscape evolves quickly, so get hands on and create your own insights
3. Task Delegation
    1. Where would augmentation benefit more than working alone?
    2. What should a human take on alone?
    3. What could be handled by an agent on your behalf?

Notes

- Planning (AI-Heavy)
- Development (Hybrid)
- Refinement (Human-Heavy)
- Delivery (Human-Only)

Effective delegation to AI in preparation follows the principle: **AI handles the "what" (information, structure,
options),
humans handle the "why" and "how" (purpose, delivery, connection)**. This ensures efficiency while maintaining
authenticity and impact.

## Description

Goals: communicate effectively with an AI

- Explain tasks, ask questions, provide context, guide the interaction
- Steer a conversation going wrong
- Guide an AI's through process or logical reasoning
- Build a thinking environment between you and the AI to do your best work

1. Product Description ("The ability to clearly define what you want the AI to create or provide")
    1. Outputs rely on how well you can describe what you want. AI's can't read your mind
        1. Example: "make dinner" vs "make dinner according to the following recipe instructions..."
    2. Think about the context required, the format the request is in, the audience intended, style, constraints
    3. Don't make the AI guess, give it the information it needs
2. Process Description ("The ability to guide an AIs thought process")
    1. **HOW** the AI approaches the job is sometimes more important than specifying **WHAT** the end goal is
        1. Examples: you may give someone a manual to figure out a task, or you may give them step-by-step instructions
           or show them an example
    2. Is there specific data you want it to consider?
    3. A priority or preference of order, key tasks or a certain style?
3. Performance Description ("The ability to define the behavioral aspects of an interaction")
    1. AI tools are not vending machines, they are **interactive environments** which act differently in different
       contexts
    2. Explain how you want the AI to behave
    3. What kind of thinking partner do you need?
        1. Do you want someone to challenge you or probe you?
        2. Someone concise and brief or thorough and creative
        3. Do you want it to explain its reasoning or why it performed certain tasks?

## Discernment

Goal: evaluate what AI produces, how it produces, and how it behaves

- Determine what you get back meeting your needs?
- Helps determine valuable vs problematic outputs
    - strengths and limitations of your models
    - helps determine when outputs are ready to use vs. needs more work
- Requires domain expertise to know enough to judge quality

1. Product Discernment ("Capacity to judge the quality of the AI output")
    1. Factually accurate or valid
    2. Appropriate for purpose?
    3. Coherent and well-structured?
    4. Does it meet the requirements?
    5. Does it add value?
2. Process Discernment ("Capacity to judge the quality of the problem solving approach")
    1. Logical errors?
    2. Inappropriate steps?
    3. Lapses in attention
    4. Stuck on a single detail?
    5. Getting trapped in circular reasoning
        1. sometimes re-inserts previously rejected ideas
    6. Making sure you and the AI are thinking in-sync through the process
    7. About having trust in the process
3. Performance Discernment ("Capacity to judge the AI behaviors")
    1. How well is the AI interacting with you while it's doing its work
    2. Is there a better way for the AI to communicate with you?
    3. Is it providing information at the right level?
    4. Is it responding to feedback in the right way?
    5. Is the interaction efficient or unnecessarily complex?
4. Feedback & Correction
    1. Specify the problem
    2. Clearly explain why it's a problem
    3. Provide concrete suggestions for improvement
    4. Revision your instructions or examples

Most AI interactions involve small loops of Description and Discernment.
Describing what we need, evaluating what we get, and refining our request.

## Diligence

Goal: taking ownership of your work and taking responsibility for the outputs
- Taking responsibility for the outputs and interactions of your AI collaboration
- Making sure your use of AI systems is not only product, but rigorous, transparent, and accountable
- Crucial in a professional environment to ask the broader questions
  - What are the implications of working with this AI?
  - Who might be affected by what is created?
  - Who has access to the data used to produce this output?
  - How do I make sure that my interactions and output align to ethical values and standards?
- For example, when driving, it's not just about getting from A to B efficiently, 
  - we also care about safety, following the rules of the road, and our effects on other drivers
- Working with AI requires awareness of broader contexts and their implications

1. Creation Diligence ("Ability to be critical and intentional about what AI systems you use")
   1. Becoming more critically thoughtful about **what** systems you work with, **how** you work with them, and the **impact** of the interaction
   2. Questions to consider:
      1. How was the model trained?
      2. What data was used?
      3. Who owns the data I'm inputting?
      4. Who may have access to the data once it's shared?
      5. How am I protecting the privacy and security of myself and others?
      6. How does this interaction align with my organization's policies?
2. Transparency Diligence ("Ability to be open and honest about your AI interactions")
   1. Who needs to know
   2. How should I communicate this?
   3. What level of detail is needed?
   4. About maintaining trust and respect between teams
   5. For example, if a teammate drafts a product proposal using AI, being open about which parts were AI assisted creates trust so everyone's on the same page
3. Deployment Diligence ("Ability to take informed responsibility for your AI's outputs")
   1. Verify facts
   2. Check for bias
   3. ensure accuracy
   4. Check for usage rights
   5. For example, if a journalist used AI to write an article, they have to verify facts, add sources, and align to journalistic integrity just as if they didn't use AI
